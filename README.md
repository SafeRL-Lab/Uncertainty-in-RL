# Uncertainty-in-RL







The repository is for Reinforcement-Learning Uncertainty research, in which we investigate various uncertain factors in RL, including single agent RL and multi-agent RL. 




***
The README is organized as follows:
- [1. Environments Supported](#1-environments-supported)
  * [1.1. Safe Single Agent RL benchmarks](#11-safe-single-agent-rl-benchmarks)
  * [1.2. Safe Multi-Agent RL benchmarks](#12-safe-multi-agent-rl-benchmarks)
- [2. Safe RL Baselines](#2-safe-rl-baselines)
  * [2.1. Safe Single Agent RL Baselines](#21-safe-single-agent-rl-baselines)
  * [2.2. Safe Multi-Agent RL Baselines](#22-safe-multi-agent-rl-baselines)
- [3. Surveys](#3-surveys)
- [4. Thesis](#4-thesis)
- [5. Book](#5-book)

***



### 1. Uncertainty in reward
#### 1.1. Inverse Reinforcement Learning 
- Apprenticeship Learning via Inverse Reinforcement Learning, [Paper](https://www.cs.utexas.edu/~sniekum/classes/RLFD-F15/papers/Abbeel04.pdf) (2004)
- Maximum Entropy Inverse Reinforcement Learning, [Paper](https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf?source=post_page---------------------------) (2008)
- Adversarial Inverse Reinforcement Learning, [Paper](https://arxiv.org/pdf/1710.11248.pdf) (2018)
- Inverse Reward Design, [Paper](https://proceedings.neurips.cc/paper/2017/file/32fdab6559cdfa4f167f8c31b9199643-Paper.pdf) (2017)

#### 1.2. Generative Adversarial Imitation Learning
- Generative Adversarial Imitation Learning, [Paper](https://proceedings.neurips.cc/paper/2016/file/cc7e2b878868cbae992d1fb743995d8f-Paper.pdf)(2016)
- A Connection Between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models, [Paper](https://arxiv.org/pdf/1611.03852.pdf?source=post_page)(2016)
- Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative Adversarial Nets, [Paper](https://arxiv.org/pdf/2005.10622.pdf)(2020)

#### 1.3. Preference-based RL 
- Deep Reinforcement Learning from Human Preferences, [Paper](https://proceedings.neurips.cc/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf)(2017)
- Reward learning from human preferences and demonstrations in Atari, [Paper](https://proceedings.neurips.cc/paper/2018/file/8cbe9ce23f42628c98f80fa0fac8b19a-Paper.pdf)(2018)
- End-to-End Robotic Reinforcement Learning without Reward Engineering, [Paper](https://arxiv.org/pdf/1904.07854.pdf)(2019)
- PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training, [Paper](https://arxiv.org/pdf/2106.05091.pdf)(2021)
- Reward uncertainty for exploration in preference-based RL, [Paper](https://arxiv.org/pdf/2205.12401.pdf)(2022)

#### 1.4. Meta-Learning 
- MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning, [Paper](http://proceedings.mlr.press/v139/li21g/li21g.pdf) (2021)




### 2. Uncertainty in transition

#### 2.1. Probabilistic Inference and Learning for Control

- PILCO: A Model-Based and Data-Efficient Approach to Policy Search, [Paper](https://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf)(2011)

- Improving PILCO with Bayesian Neural Network Dynamics Modelsï¼Œ[Paper](http://mlg.eng.cam.ac.uk/yarin/website/PDFs/DeepPILCO.pdf)(2016)


#### 2.2.Probabilistic Ensembles with Trajectory Sampling 
 
- Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models, [Paper](https://proceedings.neurips.cc/paper/2018/file/3de568f8597b94bda53149c7d7f5958c-Paper.pdf)(2018)
[Code](https://github.com/kchua/handful-of-trials)

- Variational Inference MPC for Bayesian Model-based Reinforcement Learning,  [Paper] (http://proceedings.mlr.press/v100/okada20a/okada20a.pdf)(2020)







- Robust Control of Markov Decision Processes with Uncertain Transition Matrices, [Paper](http://people.eecs.berkeley.edu/~elghaoui/Pubs/RobMDP_OR2005.pdf)(2005)
- Exploring State Transition Uncertainty in Variational Reinforcement Learning, [Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9287440)(2020)







